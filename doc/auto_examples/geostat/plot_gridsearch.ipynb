{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n# GridSearch optimization\n\nThe SciKit-GStat package can be connected to scikit-learn i.e. to use\nthe model optimization sub-package. In this example, different options\nare compared and cross-validated.\nThe Interface has two different options to evaluate a variogram model fit:\n\n* goodness of fit measures of the spatial model itself\n* cross-validation of the variogram by interpolating the observation points\n\nBoth options can use the RMSE, MSE and MAE as a metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import plotly\nimport plotly.graph_objects as go\nimport hydrobox\nfrom hydrobox.data import pancake\nfrom hydrobox.plotting import plotting_backend\nplotting_backend('plotly')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Load sample data from the data sub-module\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "df = pancake()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First, a Variogram is estimated, which will fix all arguments that\nshould not be evaluated by the Grid Search.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "vario = hydrobox.geostat.variogram(\n    coordinates=df[['x', 'y']].values,\n    values=df.z.values,\n    maxlag=500,\n    bin_func='kmeans',\n    return_type='object'\n)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The next step is to create a parameter grid, which specifies the\nvalue space for each parameter that should be checked.\nHere, we will try all combinations of different models and lag classes.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "param_grid = {\n    'model': ('spherical', 'exponential', 'matern'),\n    'n_lags': (15, 20, 25, 30, 35)\n}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "First the model fit itself is evaluated and only the best parameter\nset will be returned\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "best_param = hydrobox.geostat.gridsearch(\n    param_grid=param_grid,\n    variogram=vario,\n    coordinates=None,       # must be set if variogram is None\n    values=None,            # must be set if variogram is None\n    score='rmse',           # default\n    cross_validate=False,   # evaluate model fit,\n    n_jobs=-1,              # use parallel mode\n    return_type='best_param'\n)\n\nprint(best_param)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "It is also possible to return the underlying \n:class:`GridSearchCV <sklearn.model_selection.GridSearchCV>` instance.\nThis class holds way more information than just the best parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# reun the same Gridsearch, return the object\nclf = hydrobox.geostat.gridsearch(\n    param_grid=param_grid,\n    variogram=vario,\n    coordinates=None,       # must be set if variogram is None\n    values=None,            # must be set if variogram is None\n    score='rmse',           # default\n    cross_validate=False,   # evaluate model fit,\n    n_jobs=-1,              # use parallel mode\n    return_type='object'\n)\n\n# get the scores and their std\nscores = clf.cv_results_['mean_test_score']\nscores_std = clf.cv_results_['std_test_score']\nx = list(range(len(scores)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Plot the result\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = go.Figure()\nfig.add_trace(\n    go.Scatter(x=x, y=scores, mode='lines', line_color='#A3ACF7', name='RMSE score')\n)\nfig.add_trace(\n    go.Scatter(x=x, y=scores + scores_std, mode='lines', line_color='#BAC1F2', fill='tonexty', name='RMSE + std')\n)\nfig.add_trace(\n    go.Scatter(x=x, y=scores - scores_std, mode='lines', line_color='#BAC1F2', fill='tonexty', name='RMSE - std')\n)\nfig.update_layout(\n    template='plotly_white'\n)\n\n# show the plot\nplotly.io.show(fig)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}